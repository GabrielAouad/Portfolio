# -*- coding: utf-8 -*-
"""code-copie-finale-5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xEzp_VSy0MEt2KlN2vBF04nmBjCUqt9W
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr
from scipy.stats import spearmanr
from scipy.stats import chi2_contingency
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import plotly.graph_objects as go
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
# %matplotlib inline
from sklearn.metrics import classification_report
from sklearn.model_selection import cross_val_score

from sklearn import neighbors
from sklearn.metrics import roc_curve, auc
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier


df = pd.read_csv('bank.csv')
df.head(50)

df.info()

"""### Statistiques exploratoires"""

df.describe()

# Nombre de NaN pour chaque variable dans le DataFrame
nan_counts = df.isna().sum()
print(nan_counts)

df.duplicated().sum()

cat_col = df.select_dtypes(include=['object']).columns
print(cat_col.tolist())

# Distribution des variables continues :

plt.figure(figsize = (12,15))

plt.subplot(421)
sns.boxplot(x = 'age', data = df);
plt.subplot(422)
sns.boxplot(x = 'balance', data = df);
plt.subplot(423)
sns.boxplot(x = 'day', data = df);
plt.subplot(424)
sns.boxplot(x = 'duration', data = df);
plt.subplot(425)
sns.boxplot(x = 'campaign', data = df);
plt.subplot(426)
sns.boxplot(x = 'pdays', data = df);
plt.subplot(427)
sns.boxplot(x = 'previous', data = df);

plt.figure(figsize=(14,30))

plt.subplot(521)
sns.countplot(y = 'job', data = df);
plt.subplot(522)
sns.countplot(y = 'marital', data = df);
plt.subplot(523)
sns.countplot(y = 'education', data = df);
plt.subplot(524)
sns.countplot(y = 'default', data = df);
plt.subplot(525)
sns.countplot(y = 'housing', data = df);
plt.subplot(526)
sns.countplot(y = 'loan', data = df);
plt.subplot(527)
sns.countplot(y = 'contact', data = df);
plt.subplot(528)
sns.countplot(y = 'month', data = df);
plt.subplot(529)
sns.countplot(y = 'poutcome', data = df);
plt.subplot(5,2,10)
sns.countplot(y = 'deposit', data = df);

# Compter le nombre de clients ayant souscrit et non souscrit au dépôt
count_deposit = df['deposit'].value_counts()

# Afficher les résultats
print("Nombre de clients ayant souscrit au dépôt :", count_deposit['yes'])
print("Nombre de clients n'ayant pas souscrit au dépôt :", count_deposit['no'])

# Compter le nombre de clients ayant souscrit et non souscrit au dépôt
count_deposit = df['deposit'].value_counts()

# Créer le diagramme en camembert
labels = ['Souscrit', 'Non souscrit']
sizes = [count_deposit['yes'], count_deposit['no']]
colors = ['skyblue', 'lightcoral']
explode = (0.1, 0)  # Séparer légèrement la part "Souscrit"

plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)
plt.axis('equal')  # Rendre le camembert circulaire

# Afficher le camembert
plt.show()

"""### Tests Statistiques"""

# Sélectionner les variables quantitatives
num_col = ["age", "balance", "duration", "campaign", "pdays", "previous"]

# Réaliser le test de corrélation de Pearson pour toutes les paires de variables
cor_p = pd.DataFrame(index=num_col, columns=num_col)
for var1 in num_col:
    for var2 in num_col:
        correlation, p_value = pearsonr(df[var1], df[var2])
        cor_p.loc[var1, var2] = correlation


# Calcul de la matrice de corrélation de Pearson
correlation_p = df[num_col].corr(method="pearson")

# Affichage de la matrice de corrélation de Pearson :
correlation_p

#Création du heatmap
sns.heatmap(correlation_p, annot=True, cmap='coolwarm')
plt.title('Matrice de corrélation de Pearson')
plt.show()

# Calculer la matrice de corrélation de Spearman
correlation_s= df[num_col].corr(method="spearman")

# Afficher la matrice de corrélation
correlation_s

# Créer un heatmap avec la matrice de corrélation
sns.heatmap(correlation_s, annot=True, cmap="coolwarm")
plt.title("Heatmap - Corrélation de Spearman")
plt.show()

# Test de Corrélation de Pearson/ Spearman

# Calculer la valeur p pour le test de corrélation de Pearson
pearson_p_values = {}
for var in num_col:
    cor_p, p_value = pearsonr(df[var], df[var])
    pearson_p_values[var] = p_value

# Calculer la valeur p pour le test de corrélation de Spearman
spearman_p_values = {}
for var in num_col:
    corr, p_value = spearmanr(df[var], df[var])
    spearman_p_values[var] = p_value

# Afficher les valeurs p
print("Valeurs p pour le test de corrélation de Pearson:")
for var, p_value in pearson_p_values.items():
    print(f"{var}: {p_value}")

print("Valeurs p pour le test de corrélation de Spearman:")
for var, p_value in spearman_p_values.items():
    print(f"{var}: {p_value}")

# Filtrer les variables qualitatives
cat_col = df.select_dtypes(include=['object'])

# Afficher les variables qualitatives
print(cat_col.head())

# Test ANOVA

# Variables quantitatives
num_col = ["age", "balance", "duration", "campaign", "pdays", "previous"]

#variable cible
target = "deposit"


import statsmodels.api
result_1 = statsmodels.formula.api.ols('age ~ deposit', data=df).fit()

result_2 = statsmodels.formula.api.ols('balance ~ deposit', data=df).fit()

result_3 = statsmodels.formula.api.ols('duration~ deposit', data=df).fit()

result_4 = statsmodels.formula.api.ols('campaign ~ deposit', data=df).fit()

result_5 = statsmodels.formula.api.ols('pdays ~ deposit', data=df).fit()

result_6 = statsmodels.formula.api.ols('previous ~ deposit', data=df).fit()


print(statsmodels.api.stats.anova_lm(result_1))
print(statsmodels.api.stats.anova_lm(result_2))
print(statsmodels.api.stats.anova_lm(result_3))
print(statsmodels.api.stats.anova_lm(result_4))
print(statsmodels.api.stats.anova_lm(result_5))
print(statsmodels.api.stats.anova_lm(result_6))

# Test chi2 pour chaque variable catégorielle

for var in ['job', 'marital', 'education', 'default', 'housing', 'loan', 'month', 'campaign', 'poutcome']:
    contingency_table = pd.crosstab(df[var], df['deposit'])

    print(f"Variable : {var}")
    print(contingency_table)
    chi2, p_value, _, _ = chi2_contingency(contingency_table)
    print(f"Chi2 Statistic: {chi2}")
    print(f"P-value: {p_value}")
    print("\n")

# Charger les données à partir d'un fichier CSV (exemple)
data = pd.read_csv('bank.csv')

# Calculer le V de Cramer pour chaque variable catégorielle
variables = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'month', 'campaign', 'poutcome']
for var in variables:
    contingency_table = pd.crosstab(data[var], data['deposit'])
    chi2, _, _, _ = chi2_contingency(contingency_table)
    n = contingency_table.sum().sum()  # Taille de l'échantillon
    num_rows, num_cols = contingency_table.shape
    cramer_v = np.sqrt(chi2 / (n * min(num_rows - 1, num_cols - 1)))
    print(f"Variable: {var}")
    print(f"V de Cramer: {cramer_v}")
    print("\n")

results = [
    {'Variable': 'job', 'V de Cramer': 0.18404249757217805},
    {'Variable': 'marital', 'V de Cramer': 0.09908348866599884},
    {'Variable': 'education', 'V de Cramer': 0.1048757977683352},
    {'Variable': 'default', 'V de Cramer': 0.03994326483195487},
    {'Variable': 'housing', 'V de Cramer': 0.20370806444497289},
    {'Variable': 'loan', 'V de Cramer': 0.11031391839227384},
    {'Variable': 'month', 'V de Cramer': 0.3062355171617707},
    {'Variable': 'campaign', 'V de Cramer': 0.1472395173659391},
    {'Variable': 'poutcome', 'V de Cramer': 0.30000832876590866}
]

# Convertir les résultats en DataFrame
df_results = pd.DataFrame(results)

# Trier les résultats par ordre décroissant du coefficient de V de Cramer
df_results = df_results.sort_values(by="V de Cramer", ascending=False)

# Créer un graphique à barres pour les résultats
plt.figure(figsize=(10, 6))
sns.barplot(x="V de Cramer", y="Variable", data=df_results, palette='viridis')

# Ajouter les valeurs au-dessus des barres
for p in plt.gca().patches:
    plt.gca().annotate(f"{p.get_width():.2f}", (p.get_width(), p.get_y() + p.get_height() / 2.),
                       ha='left', va='center', xytext=(5, 0), textcoords='offset points')

# Titres et labels
plt.title("Impacte de  chaque variable catégorielle sur 'deposit' (Coefficient de V de Cramer)", fontsize=16)
plt.xlabel("Coefficient de V de Cramer", fontsize=12)
plt.ylabel("Variable", fontsize=12)

# Afficher le graphique
plt.tight_layout()
plt.show()

"""### Pré-processing

Afin d'évaluer les performances du modèle de classification, il faut isoler une partie des données qui attesteront de la qualité du modèle une fois entraîné.

Pour cela il faut systématiquement diviser les données en un ensemble d'entraînement (X_train et y_train) et un ensemble de test (X_test et y_test).
"""

#Séparation du jeu de données en deux DataFrames :

# feats : contenant les variables explicatives,
# target : contenant la variable cible deposit.

feats = df.drop('deposit', axis = 1)
target = df['deposit']

target
feats

feats

# Créer un dataframe combinant les variables explicatives et la variable cible
data_combined = pd.concat([feats, target], axis=1)

# Tracé d'un nuage de points pairplot
sns.pairplot(data_combined, hue='deposit', diag_kind='kde')
plt.title("Pairplot des variables explicatives")
plt.show()

# On constate que les  variables ne présentent pas de relation linéaire

# Séparation de la base de données en un jeu d'entraînement (X_train,y_train) et un
# jeu de test (X_test, y_test) de sorte que la partie de test contient 25% du jeu de données initial.



X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size = 0.25, random_state = 42)

# Compter le nombre d'échantillons dans chaque ensemble
train_count = len(X_train)
test_count = len(X_test)

# Création  d'une liste des valeurs pour le camembert
sizes = [train_count, test_count]

# Étiquettes pour le camembert
labels = ['Entraînement', 'Test']

# Creation du camembert
fig = go.Figure(data=[go.Pie(labels=labels, values=sizes, hole=0.7)])

# Titre
fig.update_layout(title="Répartition des ensembles d'entraînement et de test")

# représentation graphique
fig.show()

"""### Encodage des données"""

# Initialisation du LabelEncoder
le = LabelEncoder()

# Entrainement sur les données d'entrainement
y_train = le.fit_transform(y_train)

# encodage de la variable cible sur les données de Test
y_test = le.transform(y_test)

print(y_train)
print(y_test)

# Standardisation des données :
num_col

sc = StandardScaler()
X_train[num_col] = sc.fit_transform(X_train[num_col])
X_test[num_col] = sc.transform(X_test[num_col])

# Encodage des variables explicatives catégorielles :
## On utilise le OneHotEncoding car les modalités des variables catégorielles ne sont pas ordinales

cat = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']

# Encodage des variables catégorielles
X_train = pd.get_dummies(X_train, columns=cat)
X_test = pd.get_dummies(X_test, columns=cat)

# Affichage des premières lignes du DataFrame encodé
print(X_train.head())
print(X_test.head())

# verification de la taille de X_train
print(X_train.shape)

# verification de la taille de X_test
print(X_test.shape)

"""### Modélisations¶

#### Modèle de Regression Logistique
"""

# On instancie le modèle et on l'entraîne sur l'ensemble train :


reglog = LogisticRegression()
reglog.fit(X_train, y_train)
print("Score sur ensemble train :", reglog.score(X_train, y_train))
print("Score sur ensemble test :", reglog.score(X_test, y_test))

# Score d'exactitude sur l'ensemble de test et d'entraînement
train_accuracy = reglog.score(X_train, y_train)
test_accuracy = reglog.score(X_test, y_test)

# Labels pour l'axe des x
labels = ['Ensemble de test', 'Ensemble d\'entraînement']

# Valeurs d'exactitude correspondantes
accuracy_values = [test_accuracy, train_accuracy]

# Créer le graphe linéaire
plt.figure(figsize=(8, 6))
plt.plot(labels, accuracy_values, marker='o', linestyle='-', color='green')
plt.xlabel('Ensemble')
plt.ylabel('Exactitude')
plt.title('Exactitude du modèle de régression logistique')
plt.grid(True)
plt.show()

# Calcule des scores de probabilité
y_scores = reglog.predict_proba(X_test)[:, 1]

# Calculer le taux de faux positifs, le taux de vrais positifs et les seuils
fpr, tpr, thresholds = roc_curve(y_test, y_scores)

# Calculer l'aire sous la courbe ROC
roc_auc = auc(fpr, tpr)

# Tracer la courbe ROC
plt.plot(fpr, tpr, label='Courbe ROC (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'k--')  # Ligne en pointillés représentant le hasard
plt.xlabel('Taux de faux positifs')
plt.ylabel('Taux de vrais positifs')
plt.title('Courbe ROC')
plt.legend(loc='lower right')

# Afficher le graphique
plt.show()

#ce code consiste à calculer les scores de probabilité prédits par le modèle de régression logistique et à tracer manuellement la courbe
#ROC à l'aide de la bibliothèque matplotlib

# Evaluation du modèle avec le classification_report et la matrice de confusion :

y_pred_lr = reglog.predict(X_test)
print(classification_report(y_test, y_pred_lr))


"""#### Modéle RandomForest"""

# Création du classificateur et construction du modèle sur les données d'entraînement

rf = RandomForestClassifier(n_jobs=-1, random_state=42)
rf.fit(X_train, y_train)
from joblib import dump
import os

"""
Ne pas oubier de modifier le chemin d'accès

"""

# Enregistrement du modèle (à faire après l'entraînement)
save_directory = r'C:\Users\gabri\OneDrive\Bureau\Projet'

os.makedirs(save_directory, exist_ok=True)

# Create the full path for saving the model
model_filename = os.path.join(save_directory, 'randomforest.joblib')

# Dump the model to the specified path
dump(rf, model_filename)
print(f"Model saved to: {model_filename}")